########################################################################
apt repository
########################################################################

$ sudo nano /etc/apt/sources.list  
  
deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted  
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted  
deb http://mirrors.aliyun.com/ubuntu/ bionic universe  
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates universe  
deb http://mirrors.aliyun.com/ubuntu/ bionic multiverse  
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates multiverse  
deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse  
deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted  
deb http://mirrors.aliyun.com/ubuntu/ bionic-security universe 


########################################################################
generate ssh key pair
setup ssh server login and git repository without password 
########################################################################

~$ ssh-keygen -t rsa -C "cyx.1990@icloud.com"

~$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

"set up a ssh key for the remote git repository account with id_rsa.pub"

ssh login test:
~$ sudo apt-get install ssh
~$ ssh locahost

########################################################################
setup git global name and email
########################################################################

~$ (sudo apt install git)

~$ git config --global user.name "cyx"

~$ git config --global user.email "cyx.1990@icloud.com"

########################################################################
setup sgx development environment
########################################################################

software retrive:
~$ mkdir Repoes
~$ cd Repoes/
~/Repoes$ git clone git@gitee.com:fishermano/linux-sgx-driver.git
~/Repoes$ git clone git@gitee.com:fishermano/linux-sgx.git

1. sgx driver

compile and install sgx driver:
~/Repoes$ cd linux-sgx-driver
~/Repoes/linux-sgx-driver$ dpkg-query -s linux-headers-$(uname -r)
			   if not execute $ sudo apt-get install linux-headers-$(uname -r)
~/Repoes/linux-sgx-driver$ (sudo apt install gcc make)
~/Repoes/linux-sgx-driver$ make
~/Repoes/linux-sgx-driver$ sudo mkdir -p "/lib/modules/"`uname -r`"/kernel/drivers/intel/sgx"
~/Repoes/linux-sgx-driver$ sudo cp isgx.ko "/lib/modules/"`uname -r`"/kernel/drivers/intel/sgx"
~/Repoes/linux-sgx-driver$ sudo sh -c "cat /etc/modules | grep -Fxq isgx || echo isgx >> /etc/modules"
~/Repoes/linux-sgx-driver$ sudo /sbin/depmod
~/Repoes/linux-sgx-driver$ sudo /sbin/modprobe isgx
~/Repoes/linux-sgx-driver$ cd ~/Repoes

sgx driver test:
~/Repoes$ lsmod | grep isgx

uninstall sgx driver:
~/Repoes$ cd linux-sgx-driver
~/Repoes/linux-sgx-driver$ sudo /sbin/modprobe -r isgx
~/Repoes/linux-sgx-driver$ sudo rm -rf "/lib/modules/"`uname -r`"/kernel/drivers/intel/sgx"
~/Repoes/linux-sgx-driver$ sudo /sbin/depmod
~/Repoes/linux-sgx-driver$ sudo /bin/sed -i '/^isgx$/d' /etc/modules

2. sgx sdk

~/Repoes$ cd linux-sgx

install requiered tools:
~/Repoes/linux-sgx$ sudo apt-get install build-essential ocaml ocamlbuild automake autoconf libtool wget python libssl-dev git cmake perl
~/Repoes/linux-sgx$ sudo apt-get install libssl-dev libcurl4-openssl-dev protobuf-compiler libprotobuf-dev debhelper cmake reprepro

install required prebuilt binaries:
~/Repoes/linux-sgx$ ./download_prebuilt.sh

~/Repoes/linux-sgx$ sudo cp external/toolset/{as,ld,ld.gold,objdump} /usr/local/bin

build sdk installer:
~/Repoes/linux-sgx$ make sdk_install_pkg
"located at: linux/installer/bin/"

install sgx sdk:
~/Repoes/linux-sgx$ sudo ./linux/installer/bin/sgx_linux_x64_sdk_2.9.101.2.bin
"set the install directory as /opt/"
~/Repoes/linux-sgx$ sudo chown -R hadoop.root /opt/sgxsdk
~/Repoes/linux-sgx$ sudo nano /etc/profile
"append"
    export SGX_SDK=/opt/sgxsdk
    export PATH=$PATH:$SGX_SDK/bin:$SGX_SDK/bin/x64
    export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:$SGX_SDK/pkgconfig
"to /etc/profile"
~/Repoes/linux-sgx$ sudo touch /etc/ld.so.conf.d/sgx.conf
~/Repoes/linux-sgx$ sudo nano /etc/ld.so.conf.d/sgx.conf
"append"
    # sgx libs configuration
    /opt/sgxsdk/sdk_libs
"to /etc/ld.so.conf.d/sgx.conf"
~/Repoes/linux-sgx$ source /etc/profile

uninstall sgx sdk:
~/Repoes/linux-sgx$ cd /opt/sgxsdk
/opt/sgxsdk$ ./uninstall.sh

3. sgx psw 

install requiered tools:
~/Repoes/linux-sgx$ sudo apt-get install libssl-dev libcurl4-openssl-dev protobuf-compiler libprotobuf-dev debhelper cmake reprepro

build psw local Debian package repository:
~/Repoes/linux-sgx$ make deb_local_repo
"PATH_TO_LOCAL_REPO = ./linux/installer/deb/sgx_debian_local_repo"
~/Repoes/linux-sgx$ sudo nano /etc/apt/sourced.list
"append" 
    'deb [trusted=yes arch=amd64] file:/ABSOLUTE_PATH_TO_LOCAL_REPO bionic main' 
"to /etc/apt/sources.list"
~/Repoes/linux-sgx$ sudo apt update
~/Repoes/linux-sgx$ cd ~/Repoes

install sgx psw [launch service]: 
~/Repoes$ sudo apt-get install libsgx-launch libsgx-urts

install sgx psw [EPID-based attestation service]: 
~/Repoes$ sudo apt-get install libsgx-epid libsgx-urts

install sgx psw [algorithm agnostic attestation service]: 
~/Repoes$ sudo apt-get install libsgx-quote-ex libsgx-urts

uninstall sgx psw:
~/Repoes$ sudo apt-get remove libsgx-launch libsgx-epid libsgx-quote-ex libsgx-urts


########################################################################
setup hadoop development environment
########################################################################

1. java sdk

~$ cd Repoes
~/Repoes$ "download jdk 1.8 (jdk-8u151-linux-x64.tar.gz) here"
~/Repoes$ sudo tar -xzvf jdk-8u151-linux-x64.tar.gz -C /opt/

configure java environment:
~/Repoes$ sudo nano /etc/profile
"append"
    'export JAVA_HOME=/opt/jdk1.8.0_151'
    'export JRE_HOME=$JAVA_HOME/jre'
    'export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATH'
    'export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH'
"to /etc/profile"
~/Repoes$ source /etc/profile

java test:
~/Repoes$ java -version
~/Repoes$ javac -version

2. hadoop

~$ cd Repoes
~/Repoes$ "download hadoop (hadoop-3.1.0.tar.gz) here"
~/Repoes$ sudo tar -xzvf hadoop-3.1.0.tar.gz -C /opt/
~/Repoes/linux-sgx$ sudo chown -R hadoop.root /opt/hadoop-3.1.0

cofigure haddop environment:
~/Repoes$ sudo nano /etc/profile
"append"
    'export HADOOP_HOME=/opt/hadoop-3.1.0'
    'export HADOOP_MAPRED_HOME=$HADOOP_HOME'
    'export HADOOP_COMMON_HOME=$HADOOP_HOME'
    'export HADOOP_HDFS_HOME=$HADOOP_HOME'
    'export YARN_HOME=$HADOOP_HOME'
    'export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native'
    'export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH'
    'export HADOOP_install=$HADOOP_HOME'
"to /etc/profile"
~/Repoes$ source /etc/profile

hadoop test:
~/Repoes$ hadoop version

3. run hadoop 

configure core-site.xml:
~/Repoes$ sudo nano /opt/hadoop-3.1.0/etc/hadoop/core-site.xml
"append" 
    <configuration>
　　    <property>
　　　　　　<name>hadoop.tmp.dir</name>
　　　　　　<value>file:/opt/hadoop-3.1.0/tmp</value>
　　　　　　<description>Abase for other temporary directories.
　　　　　　</description>
　　    </property>
　　    <property>
　　　　　　<name>fs.defaultFS</name>
　　　　　  <value>hdfs://localhost:9000</value>
　　    </property>
    </configuration>
"to /opt/hadoop-3.1.0/etc/hadoop/core-site.xml"

configure hadoop-env.sh:
~/Repoes$ sudo nano /opt/hadoop-3.1.0/etc/hadoop/hadoop-env.sh
"modify"
    export JAVA_HOME=/opt/jdk1.8.0_151
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_COMMON_LIB_NATIVE_DIR
"to /opt/hadoop-3.1.0/etc/hadoop/hadoop-env.sh"

configure hdfs-site.xml:
~/Repoes$ sudo nano /opt/hadoop-3.1.0/etc/hadoop/hdfs-site.xml
"append"
    <configuration>
       <property>
          <name>dfs.replication</name>
          <value>1</value>
       </property>
       <property>
          <name>dfs.namenode.name.dir</name>
          <value>file:/opt/hadoop-3.1.0/tmp/dfs/name</value>
       </property>
       <property>
          <name>dfs.datanode.data.dir</name>
          <value>file:/opt/hadoop-3.1.0/tmp/dfs/data</value>
       </property>
       <property>
          <name>dfs.http.address</name>
          <value>0.0.0.0:9870</value>
       </property>
    </configuration>
"to /opt/hadoop-3.1.0/etc/hadoop/hdfs-site.xml"

configure yarn-site.xml:
~/Repoes$ sudo nano /opt/hadoop-3.1.0/etc/hadoop/yarn-site.xml
"append"
    <configuration>
       <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
       </property>
    </configuration>
"to /opt/hadoop-3.1.0/etc/hadoop/yarn-site.xml"

configure mapred-site.xml:
~/Repoes$ sudo nano /opt/hadoop-3.1.0/etc/hadoop/mapred-site.xml
"append"
    <configuration>
      <property>
         <name>mapreduce.framework.name</name>
         <value>yarn</value>
      </property>
    </configuration>
"to /opt/hadoop-3.1.0/etc/hadoop/mapred-site.xml"

format namenode:
~/Repoes$ hdfs namenode -format

start hdfs:
~/Repoes$ start-dfs.sh

run hadoop test:
~/Repoes$ jps
"access https://localhost:9870"

stop hdfs:
~/Repoes$ stop-all.sh

########################################################################
setup sbt development environment
########################################################################

~$ cd Repoes
~/Repoes$ "download sbt 0.13.17 (sbt-0.13.17.tgz) here"
~/Repoes$ sudo tar -xzvf sbt-0.13.17.tgz -C /opt/

configure sbt environment:
~/Repoes$ sudo nano /etc/profile
"append"
    'export SBT_HOME=/opt/sbt-0.13.17'
    'export PATH=$SBT_HOME/bin:$PATH'
"to /etc/profile"
~/Repoes$ source /etc/profile

sbt test:
~/Repoes$ sbt -version

configure sbt console to show current project module:
~$ touch ~/.sbt/0.13/global.sbt
~$ nano ~/.sbt/0.13/global.sbt
"append"
     import scala.Console.{BLUE, RESET, UNDERLINED}
     shellPrompt := { state =>
       val projectId = Project.extract(state).currentProject.id
       s"$BLUE sbt ($projectId)>$RESET "
"to ~/.sbt/0.13/global.sbt"

configure sbt domastic repository:
~$ touch ~/.sbt/repositories
~$ nano ~/.sbt/repositories
"append"
     [repositories]
     local
     aliyun-central: https://maven.aliyun.com/repository/central
     aliyun-google: https://maven.aliyun.com/repository/google
     aliyun-gradle-plugin: https://maven.aliyun.com/repository/gradle-plugin
     aliyun-jcenter: https://maven.aliyun.com/repository/jcenter
     aliyun-spring: https://maven.aliyun.com/repository/spring
     aliyun-spring-plugin: https://maven.aliyun.com/repository/spring-plugin
     aliyun-public: https://maven.aliyun.com/repository/public
     aliyun-releases: https://maven.aliyun.com/repository/releases
     aliyun-grails-core: https://maven.aliyun.com/repository/grails-core
     huaweicloud-maven: https://repo.huaweicloud.com/repository/maven/
     maven-central: https://repo1.maven.org/maven2/
     sbt-plugin-repo: https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext]
"to ~/.sbt/repositories"

~$ sudo nano ~$ nano ~/.sbt/repositories/sbtopts
"append"
     -Dsbt.override.build.repos=true
"to ~$ nano ~/.sbt/repositories/sbtopts"

########################################################################
setup maven development environment
########################################################################

~$ sudo apt-get install maven

configure maven environment:
~/Repoes$ sudo nano /etc/profile
"append"
     export MAVEN_HOME=/usr/share/maven
     export MAVEN_OPTS="-Xmx2048m"
"to /etc/profile"
~/Repoes$ source /etc/profile

maven test:
~/Repoes$ mvn -version

########################################################################
setup scala development environment
########################################################################

~$ cd Repoes
~/Repoes$ "download scala 2.11.12 (scala-2.11.12.tgz) here"
~/Repoes$ sudo tar -xzvf scala-2.11.12.tgz -C /opt/

configure sbt environment:
~/Repoes$ sudo nano /etc/profile
"append"
     export SCALA_HOME=/opt/scala-2.11.12
     export PATH=$SCALA_HOME/bin:$PATH
"to /etc/profile"
~/Repoes$ source /etc/profile

scala test:
~/Repoes$ scala -version

########################################################################
setup spark development environment
########################################################################

~$ git clone git@gitee.com:fishermano/spark-2.4.5.git

compile spark core module:
~$ cd spark-2.4.5
~/spark-2.4.5$ mvn package -Pyarn -Phadoop-3.1 -DskipTests -pl core

compile spark sql/core sql/catalyst modules:
~/spark-2.4.5$ mvn package -Pyarn -Phadoop-3.1 -DskipTests -pl sql/catalyst,sql/core

compile spark and produce a distribution
~/spark-2.4.5$ ./dev/make-distribution.sh --name custom-spark --tgz -Phadoop-3.1 -DskipTests

install spark:
~/spark-2.4.5$ sudo tar -zxvf spark-2.4.5-bin-custom-spark.tgz -C /opt/
~/spark-2.4.5$ cd /opt
/opt$ sudo chown -R hadoop.root spark-2.4.5-bin-custom-spark/

configure spark-env.sh:
/opt$ cd spark-2.4.5-bin-custom-spark/conf
/opt/spark-2.4.5-bin-custom-spark/conf$ cp spark-env.sh.template spark-env.sh
/opt/spark-2.4.5-bin-custom-spark/conf$ nano spark-env.sh
"append"
     export JAVA_HOME=/opt/jdk1.8.0_151
     export HADOOP_HOME=/opt/hadoop-3.1.0
     export HADOOP_CONF_DIR=/opt/hadoop-3.1.0/etc/hadoop
     export YARN_CONF_DIR=/opt/hadoop-3.1.0/etc/hadoop
     export SPARK_MASTER_IP=spark
     export SPARK_LOCAL_IP=127.0.1.1
     export SPARK_WORKER_MEMORY=4g
     export SPARK_HOME=/opt/spark-2.4.5-bin-custom-spark
     export SPARK_LOCAL_DIRS=/opt/spark-2.4.5-bin-custom-spark/tmp
     export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_HOME/lib/native
"to spark-env.sh"

configure /etc/hosts:
~$ sudo nano /etc/hosts
"append"
     127.0.1.1 spark
"to /etc/hosts"

configure slaves (stand-alone):
/opt/spark-2.4.5-bin-custom-spark/conf$ cp slaves.template slaves
/opt/spark-2.4.5-bin-custom-spark/conf$ nano slaves
"append"
     localhost
"to slaves"

configure log4j.properties (hide inessential information output to console):
/opt/spark-2.4.5-bin-custom-spark/conf$ cp log4j.properties.template log4j.properties
/opt/spark-2.4.5-bin-custom-spark/conf$ nano log4j.properties
"replace all 'INFO' with 'WARN' "

configure /etc/profile:
~$ sudo nano /etc/profile
"append"
     export SPARK_HOME=/opt/spark-2.4.5-bin-custom-spark
     export PATH=$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH
"to /etc/profile"
~$ source /etc/profile

spark test:
~/ spark-shell --master spark://spark:7077 --executor-memory 1024m --driver-memory 1024m

